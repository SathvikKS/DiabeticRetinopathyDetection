{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3cc4285-bfa4-4612-ac5f-13d10678c09a","_uuid":"725d378daf5f836d4885d67240fc7955f113309d","execution":{"iopub.execute_input":"2022-12-11T07:53:08.133930Z","iopub.status.busy":"2022-12-11T07:53:08.133567Z","iopub.status.idle":"2022-12-11T07:53:08.708150Z","shell.execute_reply":"2022-12-11T07:53:08.707446Z","shell.execute_reply.started":"2022-12-11T07:53:08.133857Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt # showing and rendering figures\n","# io related\n","from skimage.io import imread\n","import os\n","from glob import glob\n","# not needed in Kaggle, but required in Jupyter\n","%matplotlib inline "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4b38df6-ffa1-4847-b605-511e72b68231","_uuid":"346da81db6ee7a34af8da8af245b42e681f2ba48","execution":{"iopub.execute_input":"2022-12-11T07:54:50.571652Z","iopub.status.busy":"2022-12-11T07:54:50.571300Z","iopub.status.idle":"2022-12-11T07:56:15.687475Z","shell.execute_reply":"2022-12-11T07:56:15.686670Z","shell.execute_reply.started":"2022-12-11T07:54:50.571599Z"},"trusted":true},"outputs":[],"source":["base_image_dir = '../Dataset3/original/'\n","retina_df = pd.read_csv('../Dataset3/items.csv')\n","retina_df['PatientId'] = retina_df['image'].map(lambda x: x.split('_')[0])\n","retina_df['path'] = retina_df['image'].map(lambda x: os.path.join(base_image_dir,\n","                                                         '{}.jpeg'.format(x)))\n","retina_df['exists'] = retina_df['path'].map(os.path.exists)\n","print(retina_df['exists'].sum(), 'images found of', retina_df.shape[0], 'total')\n","retina_df['eye'] = retina_df['image'].map(lambda x: 1 if x.split('_')[-1]=='left' else 0)\n","from keras.utils.np_utils import to_categorical\n","retina_df['level_cat'] = retina_df['level'].map(lambda x: to_categorical(x, 1+retina_df['level'].max()))\n","\n","retina_df.dropna(inplace = True)\n","retina_df = retina_df[retina_df['exists']]\n","retina_df.sample(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1192c6b3-a940-4fa0-a498-d7e0d400a796","_uuid":"a48b300ca4d37a6e8b39f82e3c172739635e4baa","execution":{"iopub.execute_input":"2022-12-11T07:56:15.911300Z","iopub.status.busy":"2022-12-11T07:56:15.910930Z","iopub.status.idle":"2022-12-11T07:56:16.187866Z","shell.execute_reply":"2022-12-11T07:56:16.187011Z","shell.execute_reply.started":"2022-12-11T07:56:15.911237Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","rr_df = retina_df[['PatientId', 'level']].drop_duplicates()\n","train_ids, valid_ids = train_test_split(rr_df['PatientId'], \n","                                   test_size = 0.20, \n","                                   random_state = 2018,\n","                                   stratify = rr_df['level'])\n","raw_train_df = retina_df[retina_df['PatientId'].isin(train_ids)]\n","valid_df = retina_df[retina_df['PatientId'].isin(valid_ids)]\n","print('train', raw_train_df.shape[0], 'validation', valid_df.shape[0])\n","train_df = raw_train_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","ptModelName = 'DenseNet201'\n","dataSet = 'd3'\n","modelVersion = '1'\n","imageSize = '512'\n","modelName = f'{ptModelName}_{dataSet}_{imageSize}_{modelVersion}'\n","\n","if not os.path.exists('./saves/{}'.format(ptModelName)):\n","    os.mkdir('./saves/{}'.format(ptModelName))\n","else:\n","    print('exists')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9954bfda-29bd-4c4d-b526-0a972b3e43e2","_uuid":"9529ab766763a9f122786464c24ab1ebe22c6006","execution":{"iopub.execute_input":"2022-12-11T07:56:16.207868Z","iopub.status.busy":"2022-12-11T07:56:16.207617Z","iopub.status.idle":"2022-12-11T07:56:16.462496Z","shell.execute_reply":"2022-12-11T07:56:16.461823Z","shell.execute_reply.started":"2022-12-11T07:56:16.207796Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from keras import backend as K\n","from keras.applications.inception_v3 import preprocess_input\n","import numpy as np\n","IMG_SIZE = (512, 512) \n","def tf_image_loader(out_size, \n","                      horizontal_flip = True, \n","                      vertical_flip = False, \n","                     random_brightness = True,\n","                     random_contrast = True,\n","                    random_saturation = True,\n","                    random_hue = True,\n","                      color_mode = 'rgb',\n","                       preproc_func = preprocess_input,\n","                       on_batch = False):\n","    def _func(X):\n","        with tf.name_scope('image_augmentation'):\n","            with tf.name_scope('input'):\n","                X = tf.image.decode_png(tf.read_file(X), channels = 3 if color_mode == 'rgb' else 0)\n","                X = tf.image.resize_images(X, out_size)\n","            with tf.name_scope('augmentation'):\n","                if horizontal_flip:\n","                    X = tf.image.random_flip_left_right(X)\n","                if vertical_flip:\n","                    X = tf.image.random_flip_up_down(X)\n","                if random_brightness:\n","                    X = tf.image.random_brightness(X, max_delta = 0.1)\n","                if random_saturation:\n","                    X = tf.image.random_saturation(X, lower = 0.75, upper = 1.5)\n","                if random_hue:\n","                    X = tf.image.random_hue(X, max_delta = 0.15)\n","                if random_contrast:\n","                    X = tf.image.random_contrast(X, lower = 0.75, upper = 1.5)\n","                return preproc_func(X)\n","    if on_batch: \n","        def _batch_func(X, y):\n","            return tf.map_fn(_func, X), y\n","        return _batch_func\n","    else:\n","        def _all_func(X, y):\n","            return _func(X), y         \n","        return _all_func\n","    \n","def tf_augmentor(out_size,\n","                intermediate_size = (640, 640),\n","                 intermediate_trans = 'crop',\n","                 batch_size = 16,\n","                   horizontal_flip = True, \n","                  vertical_flip = False, \n","                 random_brightness = True,\n","                 random_contrast = True,\n","                 random_saturation = True,\n","                    random_hue = True,\n","                  color_mode = 'rgb',\n","                   preproc_func = preprocess_input,\n","                   min_crop_percent = 0.001,\n","                   max_crop_percent = 0.005,\n","                   crop_probability = 0.5,\n","                   rotation_range = 10):\n","    \n","    load_ops = tf_image_loader(out_size = intermediate_size, \n","                               horizontal_flip=horizontal_flip, \n","                               vertical_flip=vertical_flip, \n","                               random_brightness = random_brightness,\n","                               random_contrast = random_contrast,\n","                               random_saturation = random_saturation,\n","                               random_hue = random_hue,\n","                               color_mode = color_mode,\n","                               preproc_func = preproc_func,\n","                               on_batch=False)\n","    def batch_ops(X, y):\n","        batch_size = tf.shape(X)[0]\n","        with tf.name_scope('transformation'):\n","            transforms = []\n","            identity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\n","            if rotation_range > 0:\n","                angle_rad = rotation_range / 180 * np.pi\n","                angles = tf.random_uniform([batch_size], -angle_rad, angle_rad)\n","                transforms += [tf.contrib.image.angles_to_projective_transforms(angles, intermediate_size[0], intermediate_size[1])]\n","\n","            if crop_probability > 0:\n","                crop_pct = tf.random_uniform([batch_size], min_crop_percent, max_crop_percent)\n","                left = tf.random_uniform([batch_size], 0, intermediate_size[0] * (1.0 - crop_pct))\n","                top = tf.random_uniform([batch_size], 0, intermediate_size[1] * (1.0 - crop_pct))\n","                crop_transform = tf.stack([\n","                      crop_pct,\n","                      tf.zeros([batch_size]), top,\n","                      tf.zeros([batch_size]), crop_pct, left,\n","                      tf.zeros([batch_size]),\n","                      tf.zeros([batch_size])\n","                  ], 1)\n","                coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), crop_probability)\n","                transforms += [tf.where(coin, crop_transform, tf.tile(tf.expand_dims(identity, 0), [batch_size, 1]))]\n","            if len(transforms)>0:\n","                X = tf.contrib.image.transform(X,\n","                      tf.contrib.image.compose_transforms(*transforms),\n","                      interpolation='BILINEAR')\n","            if intermediate_trans=='scale':\n","                X = tf.image.resize_images(X, out_size)\n","            elif intermediate_trans=='crop':\n","                X = tf.image.resize_image_with_crop_or_pad(X, out_size[0], out_size[1])\n","            else:\n","                raise ValueError('Invalid Operation {}'.format(intermediate_trans))\n","            return X, y\n","    def _create_pipeline(in_ds):\n","        batch_ds = in_ds.map(load_ops, num_parallel_calls=4).batch(batch_size)\n","        return batch_ds.map(batch_ops)\n","    return _create_pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b5767f42-da63-4737-8f50-749c1a25aa84","_uuid":"07851e798db3d89ba13db7d4b56ab2b759221464","execution":{"iopub.execute_input":"2022-12-11T07:56:30.290459Z","iopub.status.busy":"2022-12-11T07:56:30.290120Z","iopub.status.idle":"2022-12-11T07:56:30.306019Z","shell.execute_reply":"2022-12-11T07:56:30.305165Z","shell.execute_reply.started":"2022-12-11T07:56:30.290390Z"},"trusted":true},"outputs":[],"source":["def flow_from_dataframe(idg, \n","                        in_df, \n","                        path_col,\n","                        y_col, \n","                        shuffle = True, \n","                        color_mode = 'rgb'):\n","    files_ds = tf.data.Dataset.from_tensor_slices((in_df[path_col].values, \n","                                                   np.stack(in_df[y_col].values,0)))\n","    in_len = in_df[path_col].values.shape[0]\n","    while True:\n","        if shuffle:\n","            files_ds = files_ds.shuffle(in_len) \n","        \n","        next_batch = idg(files_ds).repeat().make_one_shot_iterator().get_next()\n","        for i in range(max(in_len//32,1)):\n","            yield K.get_session().run(next_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"810bd229-fec9-43c4-b3bd-afd62e3e9552","_uuid":"1848f5048a9e00668c3778a85deea97f980e4f1c","execution":{"iopub.execute_input":"2022-12-11T07:56:33.122038Z","iopub.status.busy":"2022-12-11T07:56:33.121739Z","iopub.status.idle":"2022-12-11T07:56:33.133743Z","shell.execute_reply":"2022-12-11T07:56:33.132952Z","shell.execute_reply.started":"2022-12-11T07:56:33.121985Z"},"trusted":true},"outputs":[],"source":["batch_size = 24\n","core_idg = tf_augmentor(out_size = IMG_SIZE, \n","                        color_mode = 'rgb', \n","                        vertical_flip = True,\n","                        crop_probability=0.0,\n","                        batch_size = batch_size) \n","valid_idg = tf_augmentor(out_size = IMG_SIZE, color_mode = 'rgb', \n","                         crop_probability=0.0, \n","                         horizontal_flip = False, \n","                         vertical_flip = False, \n","                         random_brightness = False,\n","                         random_contrast = False,\n","                         random_saturation = False,\n","                         random_hue = False,\n","                         rotation_range = 0,\n","                        batch_size = batch_size)\n","\n","train_gen = flow_from_dataframe(core_idg, train_df, \n","                             path_col = 'path',\n","                            y_col = 'level_cat')\n","\n","valid_gen = flow_from_dataframe(valid_idg, valid_df, \n","                             path_col = 'path',\n","                            y_col = 'level_cat')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6810407e25b887dd8b352f1e46fb3faceaa58ab7","execution":{"iopub.execute_input":"2022-12-11T07:56:37.302924Z","iopub.status.busy":"2022-12-11T07:56:37.302632Z","iopub.status.idle":"2022-12-11T07:56:43.714621Z","shell.execute_reply":"2022-12-11T07:56:43.713895Z","shell.execute_reply.started":"2022-12-11T07:56:37.302869Z"},"trusted":true},"outputs":[],"source":["t_x, t_y = next(valid_gen)\n","fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\n","for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n","    c_ax.imshow(np.clip(c_x*127+127, 0, 255).astype(np.uint8))\n","    c_ax.set_title('Severity {}'.format(np.argmax(c_y, -1)))\n","    c_ax.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2d62234f-aeb0-4eba-8a38-d713d819abf6","_uuid":"8190b4ad60d49fa65af074dd138a19cb8787e983","execution":{"iopub.execute_input":"2022-12-11T07:56:43.715727Z","iopub.status.busy":"2022-12-11T07:56:43.715500Z","iopub.status.idle":"2022-12-11T07:56:55.843998Z","shell.execute_reply":"2022-12-11T07:56:55.843235Z","shell.execute_reply.started":"2022-12-11T07:56:43.715690Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["t_x, t_y = next(train_gen)\n","fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\n","for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n","    c_ax.imshow(np.clip(c_x*127+127, 0, 255).astype(np.uint8))\n","    c_ax.set_title('Severity {}'.format(np.argmax(c_y, -1)))\n","    c_ax.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eeb36110-0cde-4450-a43c-b8f707adb235","_uuid":"1f0dfaccda346d7bc4758e7329d61028d254a8d6","execution":{"iopub.execute_input":"2022-12-11T07:57:03.275984Z","iopub.status.busy":"2022-12-11T07:57:03.275683Z","iopub.status.idle":"2022-12-11T07:57:28.686048Z","shell.execute_reply":"2022-12-11T07:57:28.685363Z","shell.execute_reply.started":"2022-12-11T07:57:03.275926Z"},"trusted":true},"outputs":[],"source":["# from keras.applications.vgg16 import VGG16 as PTModel\n","# from keras.applications.inception_resnet_v2 import InceptionResNetV2 as PTModel\n","# from keras.applications.inception_v3 import InceptionV3 as PTModel\n","# from keras.applications.inception_resnet_v2 import InceptionResNetV2 as PTModel\n","# from keras.applications.densenet import DenseNet201 as PTModel\n","from keras.applications.nasnet import NASNetLarge as PTModel\n","from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda\n","from keras.models import Model\n","in_lay = Input(t_x.shape[1:])\n","base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], include_top = False, weights = 'imagenet')\n","base_pretrained_model.trainable = False\n","pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n","pt_features = base_pretrained_model(in_lay)\n","from keras.layers import BatchNormalization\n","bn_features = BatchNormalization()(pt_features)\n","\n","\n","attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(Dropout(0.5)(bn_features))\n","attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n","attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n","attn_layer = Conv2D(1, \n","                    kernel_size = (1,1), \n","                    padding = 'valid', \n","                    activation = 'sigmoid')(attn_layer)\n","\n","up_c2_w = np.ones((1, 1, 1, pt_depth))\n","up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n","               activation = 'linear', use_bias = False, weights = [up_c2_w])\n","up_c2.trainable = False\n","attn_layer = up_c2(attn_layer)\n","\n","mask_features = multiply([attn_layer, bn_features])\n","gap_features = GlobalAveragePooling2D()(mask_features)\n","gap_mask = GlobalAveragePooling2D()(attn_layer)\n","gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n","gap_dr = Dropout(0.25)(gap)\n","dr_steps = Dropout(0.25)(Dense(128, activation = 'relu')(gap_dr))\n","out_layer = Dense(t_y.shape[-1], activation = 'softmax')(dr_steps)\n","retina_model = Model(inputs = [in_lay], outputs = [out_layer])\n","from keras.metrics import top_k_categorical_accuracy\n","def top_2_accuracy(in_gt, in_pred):\n","    return top_k_categorical_accuracy(in_gt, in_pred, k=2)\n","\n","retina_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n","                           metrics = ['categorical_accuracy', top_2_accuracy])\n","retina_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17803ae1-bed8-41a4-9a2c-e66287a24830","_uuid":"48b9764e16fb5af52aed35c82bae6299e67d5bc7","execution":{"iopub.execute_input":"2022-12-11T07:57:28.725524Z","iopub.status.busy":"2022-12-11T07:57:28.722790Z","iopub.status.idle":"2022-12-11T07:57:28.741543Z","shell.execute_reply":"2022-12-11T07:57:28.740802Z","shell.execute_reply.started":"2022-12-11T07:57:28.725372Z"},"trusted":true},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n","weight_path=\"./saves/{}/{}_weights.best.hdf5\".format(ptModelName,modelName)\n","\n","checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n","                             save_best_only=True, mode='min', save_weights_only = True)\n","\n","reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\n","early = EarlyStopping(monitor=\"val_loss\", \n","                      mode=\"min\", \n","                      patience=6)\n","callbacks_list = [checkpoint, early, reduceLROnPlat]"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58a75586-442b-4804-84a6-d63d5a42ea14","_uuid":"b2148479bfe41c5d9fd0faece4c75adea509dabe","execution":{"iopub.execute_input":"2022-12-11T07:57:30.076350Z","iopub.status.busy":"2022-12-11T07:57:30.076061Z"},"trusted":true},"outputs":[],"source":["retina_model.fit_generator(train_gen, \n","                        steps_per_epoch = train_df.shape[0]//batch_size,\n","                        validation_data = valid_gen, \n","                        validation_steps = valid_df.shape[0]//batch_size,\n","                            epochs = 25, \n","                            callbacks = callbacks_list,\n","                            workers = 0, \n","                            use_multiprocessing=False, \n","                            max_queue_size = 0\n","                        )"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d0c45b0-bb23-48d2-83eb-bc3990043e26","_uuid":"3a90f05dd206cd76c72d8c6278ebb93da41ee45f","trusted":true},"outputs":[],"source":["retina_model.load_weights(weight_path)\n","retina_model.save(\"./saves/{}/{}_model.h5\".format(ptModelName,modelName))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow.python.keras import backend as K\n","def relu6(x):\n","  return K.relu(x, max_value=6)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from keras.metrics import top_k_categorical_accuracy\n","def top_2_accuracy(in_gt, in_pred):\n","    return top_k_categorical_accuracy(in_gt, in_pred, k=2)\n","from keras.models import load_model\n","retina_model = load_model(\"./saves/{}/{}_model.h5\".format(ptModelName,modelName), custom_objects={'top_2_accuracy':top_2_accuracy})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from keras.models import Model\n","def freeze_layers(model):\n","    for i in model.layers:\n","        i.trainable = False\n","        if isinstance(i, Model):\n","            freeze_layers(i)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_freezed = freeze_layers(retina_model)\n","model_freezed.save('./saves/DenseNet201/DenseNet201_d3_512_1_model_frozen.tf')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f37dd4d8-ecd6-487a-90d8-74fe14a9a318","_uuid":"2b74f4ab850c6e82549d732b6f0524724b95b53c","trusted":true},"outputs":[],"source":["from tqdm import tqdm_notebook\n","valid_gen = flow_from_dataframe(valid_idg, valid_df, \n","                             path_col = 'path',\n","                            y_col = 'level_cat') \n","vbatch_count = (valid_df.shape[0]//batch_size-1)\n","out_size = vbatch_count*batch_size\n","test_X = np.zeros((out_size,)+t_x.shape[1:], dtype = np.float32)\n","test_Y = np.zeros((out_size,)+t_y.shape[1:], dtype = np.float32)\n","for i, (c_x, c_y) in zip(tqdm_notebook(range(vbatch_count)), \n","                         valid_gen):\n","    j = i*batch_size\n","    test_X[j:(j+c_x.shape[0])] = c_x\n","    test_Y[j:(j+c_x.shape[0])] = c_y"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0edaf00-4b7c-4f65-af0b-e5a03b9b8428","_uuid":"b421b6183b1919a7414482f0b1ac611079e45174","trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, classification_report\n","pred_Y = retina_model.predict(test_X, batch_size = 32, verbose = True)\n","pred_Y_cat = np.argmax(pred_Y, -1)\n","test_Y_cat = np.argmax(test_Y, -1)\n","print('Accuracy on Test Data: %2.2f%%' % (accuracy_score(test_Y_cat, pred_Y_cat)))\n","print(classification_report(test_Y_cat, pred_Y_cat))"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"15189df2-3fed-495e-9661-97bb2b712dfd","_uuid":"10162e055ca7cd52878a289bab377231787ab732","trusted":true},"outputs":[],"source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","sns.heatmap(confusion_matrix(test_Y_cat, pred_Y_cat), \n","            annot=True, fmt=\"d\", cbar = False, cmap = plt.cm.Blues, vmax = test_X.shape[0]//16)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"829475ab-7db2-4421-b9ad-1a51971fd459","_uuid":"2b2aaee6c83043f721b0c9ed5bc4229eb7165200","trusted":true},"outputs":[],"source":["\n","from sklearn.metrics import roc_curve, roc_auc_score\n","sick_vec = test_Y_cat>0\n","sick_score = np.sum(pred_Y[:,1:],1)\n","fpr, tpr, _ = roc_curve(sick_vec, sick_score)\n","fig, ax1 = plt.subplots(1,1, figsize = (6, 6), dpi = 150)\n","ax1.plot(fpr, tpr, 'b.-', label = 'Model Prediction (AUC: %2.2f)' % roc_auc_score(sick_vec, sick_score))\n","ax1.plot(fpr, fpr, 'g-', label = 'Random Guessing')\n","ax1.legend()\n","ax1.set_xlabel('False Positive Rate')\n","ax1.set_ylabel('True Positive Rate')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c34f049f-b032-45bf-9d5e-a756ecc46a82","_uuid":"ba87d0e7c3a77181487b99ca64d13de2aa8a21ee","trusted":true},"outputs":[],"source":["fig, m_axs = plt.subplots(2, 4, figsize = (32, 20))\n","for (idx, c_ax) in enumerate(m_axs.flatten()):\n","    c_ax.imshow(np.clip(test_X[idx]*127+127,0 , 255).astype(np.uint8), cmap = 'bone')\n","    print(['Predicted %02d (%04.1f%%): %s' % (k, 100*v, '*'*int(10*v)) for k, v in sorted(enumerate(pred_Y[idx]), key = lambda x: -1*x[1])])\n","    print(sorted(enumerate(pred_Y[idx])))\n","    print('\\n\\n')\n","    c_ax.set_title('Actual Severity: {}\\n{}'.format(test_Y_cat[idx], \n","                                                           '\\n'.join(['Predicted %02d (%04.1f%%): %s' % (k, 100*v, '*'*int(10*v)) for k, v in sorted(enumerate(pred_Y[idx]), key = lambda x: -1*x[1])])), loc='left')\n","    c_ax.axis('off')\n","fig.savefig(f'./saves/{ptModelName}/{modelName}_img_predictions_reval_2.png', dpi = 300)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2e189dc-f80a-4b16-bb1d-5c05a155a80b","_uuid":"eb6752295030ba512263433f8383711e4ca1c14c","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"kaggle","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"6ead11fab8159dea8a79640a0ec04d416d2579d6af7ff9572439cc9d9bb24db2"}}},"nbformat":4,"nbformat_minor":4}
